{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcnoa8jdWXTb"
   },
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFghjoOyWXTc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4a9fqcW4WXTi",
    "outputId": "e36ce8b6-03ee-4d26-b3f5-ac0abc506fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "\n",
    "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "  X_train = data['x_train']\n",
    "  y_train = data['y_train']\n",
    "  X_test = data['x_test']\n",
    "  y_test = data['y_test']\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hnldvqhWXTo"
   },
   "source": [
    "## The data is prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVWFK_ALWXTp"
   },
   "source": [
    "1 Estimate MNIST SGDClassifier to distinguish digits 3 and 5 from other digits. Report average precision rate when the recall = 75% (you can round up the recall value up to the 3rd digit). Use cv = 3. Use random_state = 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lHLqc08WXTp"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDlleTn0WXTu"
   },
   "outputs": [],
   "source": [
    "# Get fit statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xf8Dx3HmWXTx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUxt2LT_WXT0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5jdu3SFWXT3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plGbIaFFWXT5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iooIqxMnWXT7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b__x6rgSWXT-"
   },
   "source": [
    "## Problem 2 \n",
    "Plot Precision-recall curve for the fit statistics from the problem 1 showing precision between 60% and 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYdv_YJuWXT-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nv5RMB0iWXUA"
   },
   "source": [
    "## Problem 3 \n",
    "What is the threshold that maximizes precision + recall from the previous problem? Report the threshold and maximum precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJme-1ipWXUA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ugY4-NAWXUD"
   },
   "source": [
    "**Load Titanic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzCj-RsxWXUF"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "train_data.head()\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "# create missing data to fill\n",
    "data = train_data.append(test_data)\n",
    "data.loc[[1,3,4,46,56,111,245], 'fare'] = np.nan\n",
    "data.loc[[6,34,12,51,46,211,145],'n_siblings_spouses'] = np.nan\n",
    "data.loc[[7,24,32,54,26,231,125], 'class'] = np.nan\n",
    "data.loc[[9,39,19,59,49,219,195], 'deck'] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJuPBhvPWXUH"
   },
   "source": [
    "The attributes have the following meaning:\n",
    "\n",
    "Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "Pclass: passenger class.\n",
    "Name, Sex, Age: self-explanatory\n",
    "SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "Parch: how many children & parents of the passenger aboard the Titanic.\n",
    "Ticket: ticket id\n",
    "Fare: price paid (in pounds)\n",
    "Cabin: passenger's cabin number\n",
    "Embarked: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMaHAoVJWXUI"
   },
   "source": [
    "## Problem 4\n",
    "Build a pipeline to impute missing data for [\"age\", \"n_siblings_spouses\", \"parch\", \"fare\"]. Also impute missing categorical variables [\"class\", 'deck', embark_town'] and convert them into indicator variables. Don't use ['sex', 'alone']. Merge them together, so that final data set have 7 features. Convert descrete variables to binary indicators using OneHot. Create vectors for training and testing data. Use \"Survived\" as a predictor and the rest of the variables as features. Transform merged training and test data in one pipeline and then divide the transformed data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bo5-0wflWXUI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hwqSy1AWXUK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msPAu1y7WXUL"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hA86JUGKWXUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "bSCty2AsWXUO"
   },
   "source": [
    "## Problem 5\n",
    " estimate data predicting survival using SDG classifier (loss='log') and logit to train model on the training data and test on testing data. Report ROC AUC score for each model. Set random_state = 42. method=\"predict_proba\", to make results comparable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huAsECWTWXUO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFtDjZyv3qUi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8FiAavCDWXUQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPqxWDv9WXUR"
   },
   "source": [
    "## Problem 6\n",
    "Repeat the same exerise as before, but instead of predicting probability of survival predict class, i.e., don't use  method=\"predict_proba\". Which method is better? How do you explain the difference between the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CigyncpNWXUR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX90t_GAWXUS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0gb_lXkWXUT"
   },
   "source": [
    "Answer: The relative ranking is the same: Logistic performs better. However, both methods perform poorly. When predicting probabilities weak probability of survival would have a score of 0.6, so if this prediction would be erroneous the error is just (0.6 -0) = 0.6. However, if we are predicting classes, then the probability of 0.6 would be classified as survived, then the error would be higher (1 - 0) = 1. This difference does not affect predictions with very high or very low probabilities, as in these cases the difference between probabilities and classes would be very small.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGV_hlvlWXUU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jWQzVZaWXUV"
   },
   "source": [
    "## Problem 7\n",
    "Use Titanic data and model estimated in the problem 6 using logit. Show confusion matrix for each model. Describe the most typical error each model has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIYBSh6nWXUV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CSTVl4bWXUX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
